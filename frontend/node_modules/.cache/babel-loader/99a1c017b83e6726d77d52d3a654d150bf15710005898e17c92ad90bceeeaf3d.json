{"ast":null,"code":"/**\r\n * Start recording audio from microphone\r\n * \r\n * @returns {Promise} - Object containing the MediaRecorder and audio chunks array\r\n */\nexport const startRecording = async () => {\n  // Request microphone access\n  const stream = await navigator.mediaDevices.getUserMedia({\n    audio: true\n  });\n\n  // Create array to store audio chunks\n  const chunks = [];\n\n  // Create MediaRecorder instance\n  const recorder = new MediaRecorder(stream);\n\n  // Add data to chunks when available\n  recorder.ondataavailable = e => {\n    if (e.data.size > 0) {\n      chunks.push(e.data);\n    }\n  };\n\n  // Start recording\n  recorder.start();\n  return {\n    recorder,\n    chunks\n  };\n};\n\n/**\r\n * Stop audio recording\r\n * \r\n * @param {MediaRecorder} recorder - The active MediaRecorder instance\r\n */\nexport const stopRecording = recorder => {\n  // Stop the recorder if it's recording\n  if (recorder && recorder.state === 'recording') {\n    recorder.stop();\n\n    // Stop all audio tracks to release the microphone\n    recorder.stream.getTracks().forEach(track => track.stop());\n  }\n};\n\n/**\r\n * Convert audio data to WAV format\r\n * (Note: In a production app, you might want a more robust solution)\r\n * \r\n * @param {Blob} audioBlob - The audio data as a Blob\r\n * @returns {Promise} - Promise resolving to WAV blob\r\n */\nexport const convertToWav = async audioBlob => {\n  // In a real application, you'd do proper audio conversion here.\n  // For this demo, we'll just return the blob as we're using WAV format by default.\n  return audioBlob;\n};\n\n/**\r\n * Play audio from base64 string\r\n * \r\n * @param {string} base64Audio - Base64 encoded audio data\r\n * @returns {HTMLAudioElement} - The audio element playing the sound\r\n */\nexport const playAudioFromBase64 = base64Audio => {\n  // Create audio element\n  const audio = new Audio(`data:audio/mpeg;base64,${base64Audio}`);\n\n  // Play the audio\n  audio.play().catch(err => {\n    console.error('Failed to play audio:', err);\n  });\n  return audio;\n};","map":{"version":3,"names":["startRecording","stream","navigator","mediaDevices","getUserMedia","audio","chunks","recorder","MediaRecorder","ondataavailable","e","data","size","push","start","stopRecording","state","stop","getTracks","forEach","track","convertToWav","audioBlob","playAudioFromBase64","base64Audio","Audio","play","catch","err","console","error"],"sources":["D:/csvoicev2/frontend/src/services/voiceService.js"],"sourcesContent":["/**\r\n * Start recording audio from microphone\r\n * \r\n * @returns {Promise} - Object containing the MediaRecorder and audio chunks array\r\n */\r\nexport const startRecording = async () => {\r\n    // Request microphone access\r\n    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\r\n    \r\n    // Create array to store audio chunks\r\n    const chunks = [];\r\n    \r\n    // Create MediaRecorder instance\r\n    const recorder = new MediaRecorder(stream);\r\n    \r\n    // Add data to chunks when available\r\n    recorder.ondataavailable = (e) => {\r\n      if (e.data.size > 0) {\r\n        chunks.push(e.data);\r\n      }\r\n    };\r\n    \r\n    // Start recording\r\n    recorder.start();\r\n    \r\n    return { recorder, chunks };\r\n  };\r\n  \r\n  /**\r\n   * Stop audio recording\r\n   * \r\n   * @param {MediaRecorder} recorder - The active MediaRecorder instance\r\n   */\r\n  export const stopRecording = (recorder) => {\r\n    // Stop the recorder if it's recording\r\n    if (recorder && recorder.state === 'recording') {\r\n      recorder.stop();\r\n      \r\n      // Stop all audio tracks to release the microphone\r\n      recorder.stream.getTracks().forEach(track => track.stop());\r\n    }\r\n  };\r\n  \r\n  /**\r\n   * Convert audio data to WAV format\r\n   * (Note: In a production app, you might want a more robust solution)\r\n   * \r\n   * @param {Blob} audioBlob - The audio data as a Blob\r\n   * @returns {Promise} - Promise resolving to WAV blob\r\n   */\r\n  export const convertToWav = async (audioBlob) => {\r\n    // In a real application, you'd do proper audio conversion here.\r\n    // For this demo, we'll just return the blob as we're using WAV format by default.\r\n    return audioBlob;\r\n  };\r\n  \r\n  /**\r\n   * Play audio from base64 string\r\n   * \r\n   * @param {string} base64Audio - Base64 encoded audio data\r\n   * @returns {HTMLAudioElement} - The audio element playing the sound\r\n   */\r\n  export const playAudioFromBase64 = (base64Audio) => {\r\n    // Create audio element\r\n    const audio = new Audio(`data:audio/mpeg;base64,${base64Audio}`);\r\n    \r\n    // Play the audio\r\n    audio.play().catch(err => {\r\n      console.error('Failed to play audio:', err);\r\n    });\r\n    \r\n    return audio;\r\n  };"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMA,cAAc,GAAG,MAAAA,CAAA,KAAY;EACtC;EACA,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;IAAEC,KAAK,EAAE;EAAK,CAAC,CAAC;;EAEzE;EACA,MAAMC,MAAM,GAAG,EAAE;;EAEjB;EACA,MAAMC,QAAQ,GAAG,IAAIC,aAAa,CAACP,MAAM,CAAC;;EAE1C;EACAM,QAAQ,CAACE,eAAe,GAAIC,CAAC,IAAK;IAChC,IAAIA,CAAC,CAACC,IAAI,CAACC,IAAI,GAAG,CAAC,EAAE;MACnBN,MAAM,CAACO,IAAI,CAACH,CAAC,CAACC,IAAI,CAAC;IACrB;EACF,CAAC;;EAED;EACAJ,QAAQ,CAACO,KAAK,CAAC,CAAC;EAEhB,OAAO;IAAEP,QAAQ;IAAED;EAAO,CAAC;AAC7B,CAAC;;AAED;AACF;AACA;AACA;AACA;AACE,OAAO,MAAMS,aAAa,GAAIR,QAAQ,IAAK;EACzC;EACA,IAAIA,QAAQ,IAAIA,QAAQ,CAACS,KAAK,KAAK,WAAW,EAAE;IAC9CT,QAAQ,CAACU,IAAI,CAAC,CAAC;;IAEf;IACAV,QAAQ,CAACN,MAAM,CAACiB,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACH,IAAI,CAAC,CAAC,CAAC;EAC5D;AACF,CAAC;;AAED;AACF;AACA;AACA;AACA;AACA;AACA;AACE,OAAO,MAAMI,YAAY,GAAG,MAAOC,SAAS,IAAK;EAC/C;EACA;EACA,OAAOA,SAAS;AAClB,CAAC;;AAED;AACF;AACA;AACA;AACA;AACA;AACE,OAAO,MAAMC,mBAAmB,GAAIC,WAAW,IAAK;EAClD;EACA,MAAMnB,KAAK,GAAG,IAAIoB,KAAK,CAAC,0BAA0BD,WAAW,EAAE,CAAC;;EAEhE;EACAnB,KAAK,CAACqB,IAAI,CAAC,CAAC,CAACC,KAAK,CAACC,GAAG,IAAI;IACxBC,OAAO,CAACC,KAAK,CAAC,uBAAuB,EAAEF,GAAG,CAAC;EAC7C,CAAC,CAAC;EAEF,OAAOvB,KAAK;AACd,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}